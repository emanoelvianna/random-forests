{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprendizado Ensemble - Florestas Aleatórias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Desenvolvimento do algoritmo de indução de uma árvore de decisão, usando como critério de seleção de atributos para divisão de nós o **Ganho de Informação (baseado no conceito de entropia)**. **Tratando tanto atributos categóricos quanto numéricos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Construindo a árvore:\n",
      "[INFO] entropy 0.9709505944546686\n",
      "[INFO] entropy 0.0\n",
      "[INFO] entropy 0.8112781244591328\n",
      "[INFO] entropy 0.9182958340544896\n",
      "[INFO] entropy 0.7219280948873623\n",
      "[INFO] entropy 0.8112781244591328\n",
      "[INFO] entropy 1.0\n",
      "[INFO] entropy 0.6500224216483541\n",
      "[INFO] entropy 0.863120568566631\n",
      "[INFO] entropy 0.9709505944546686\n",
      "[INFO] best_attribute:  Tempo\n",
      "[INFO] entropy 0.0\n",
      "[INFO] entropy 1.0\n",
      "[INFO] entropy 0.0\n",
      "[INFO] entropy 0.0\n",
      "[INFO] entropy 0.0\n",
      "[INFO] entropy 0.9182958340544896\n",
      "[INFO] entropy 1.0\n",
      "[INFO] best_attribute:  Umidade\n",
      "[INFO] entropy 0.0\n",
      "[INFO] entropy 1.0\n",
      "[INFO] entropy 0.0\n",
      "[INFO] entropy 0.9182958340544896\n",
      "[INFO] entropy 0.0\n",
      "[INFO] entropy 0.0\n",
      "[INFO] best_attribute:  Ventoso\n",
      "('Tempo', {'Ensolarado': ('Umidade', {'Alta': False, 'Normal': True}), 'Nublado': True, 'Chuvoso': ('Ventoso', {'no': True, 'yes': False})})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from functools import partial\n",
    "import math, random\n",
    "\n",
    "def entropy(class_probabilities):\n",
    "    \"\"\"given a list of class probabilities, compute the entropy\"\"\"\n",
    "    return sum(-p * math.log(p, 2) for p in class_probabilities if p)\n",
    "\n",
    "def gini_criterion(data, labels):\n",
    "  \"\"\" Gini Index\n",
    "  Parameters\n",
    "  ----------\n",
    "  data: numpy array-like = [n_samples, n_features]\n",
    "  labels: numpy array-like, shape = [n_samples]\n",
    "  \n",
    "  Return\n",
    "  ------\n",
    "  gini: float\n",
    "  \"\"\"\n",
    "  classes = np.unique(labels)\n",
    "  \n",
    "  s = 0\n",
    "  for c in classes:\n",
    "    p = np.mean(labels == c)\n",
    "    s += p * (1 - p)\n",
    "    \n",
    "  return s\n",
    "\n",
    "def class_probabilities(labels):\n",
    "    total_count = len(labels)\n",
    "    return [count / total_count\n",
    "            for count in Counter(labels).values()]\n",
    "\n",
    "def data_entropy(labeled_data):\n",
    "    labels = [label for _, label in labeled_data]\n",
    "    probabilities = class_probabilities(labels)\n",
    "    print('[INFO] entropy', entropy(probabilities))\n",
    "    return entropy(probabilities)\n",
    "\n",
    "def partition_entropy(subsets):\n",
    "    \"\"\"find the entropy from this partition of data into subsets\"\"\"\n",
    "    total_count = sum(len(subset) for subset in subsets)\n",
    "\n",
    "    #print('[INFO] subset: ', subsets)\n",
    "    return sum( data_entropy(subset) * len(subset) / total_count\n",
    "                for subset in subsets )\n",
    "\n",
    "def group_by(items, key_fn):\n",
    "    \"\"\"returns a defaultdict(list), where each input item\n",
    "    is in the list whose key is key_fn(item)\"\"\"\n",
    "    groups = defaultdict(list)\n",
    "    for item in items:\n",
    "        key = key_fn(item)\n",
    "        groups[key].append(item)\n",
    "    return groups\n",
    "\n",
    "def partition_by(inputs, attribute):\n",
    "    \"\"\"returns a dict of inputs partitioned by the attribute\n",
    "    each input is a pair (attribute_dict, label)\"\"\"\n",
    "    return group_by(inputs, lambda x: x[0][attribute])\n",
    "\n",
    "def partition_entropy_by(inputs, attribute):\n",
    "    \"\"\"computes the entropy corresponding to the given partition\"\"\"\n",
    "    partitions = partition_by(inputs, attribute)\n",
    "    return partition_entropy(partitions.values())\n",
    "\n",
    "def build_tree_id3(inputs, split_candidates=None):\n",
    "\n",
    "    # if this is our first pass,\n",
    "    # all keys of the first input are split candidates\n",
    "    if split_candidates is None:\n",
    "        split_candidates = inputs[0][0].keys()\n",
    "    #print(split_candidates)\n",
    "\n",
    "    # count Trues and Falses in the inputs\n",
    "    num_inputs = len(inputs)\n",
    "    num_trues = len([label for item, label in inputs if label])\n",
    "    num_falses = num_inputs - num_trues\n",
    "\n",
    "    if num_trues == 0:                  # if only Falses are left\n",
    "        return False                    # return a \"False\" leaf\n",
    "\n",
    "    if num_falses == 0:                 # if only Trues are left\n",
    "        return True                     # return a \"True\" leaf\n",
    "\n",
    "    if not split_candidates:            # if no split candidates left\n",
    "        return num_trues >= num_falses  # return the majority leaf\n",
    "\n",
    "    # otherwise, split on the best attribute\n",
    "    best_attribute = min(split_candidates,\n",
    "        key=partial(partition_entropy_by, inputs))\n",
    "    print('[INFO] best_attribute: ', best_attribute)\n",
    "\n",
    "    partitions = partition_by(inputs, best_attribute)\n",
    "    new_candidates = [a for a in split_candidates\n",
    "                      if a != best_attribute]\n",
    "\n",
    "    # recursively build the subtrees\n",
    "    subtrees = { attribute : build_tree_id3(subset, new_candidates)\n",
    "                 for attribute, subset in partitions.items() }\n",
    "\n",
    "    #subtrees[None] = num_trues > num_falses # default case\n",
    "\n",
    "    return (best_attribute, subtrees)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # inputs contendo tupulas contendo dicionarios\n",
    "    inputs = [\n",
    "        ({'Tempo':'Ensolarado','Temperatura':'Quente','Umidade':'Alta','Ventoso':'no'},   False),\n",
    "        ({'Tempo':'Ensolarado','Temperatura':'Quente','Umidade':'Alta','Ventoso':'yes'},  False),\n",
    "        ({'Tempo':'Nublado','Temperatura':'Quente','Umidade':'Alta','Ventoso':'no'},     True),\n",
    "        ({'Tempo':'Chuvoso','Temperatura':'Amena','Umidade':'Alta','Ventoso':'no'},  True),\n",
    "        ({'Tempo':'Chuvoso','Temperatura':'Fria','Umidade':'Normal','Ventoso':'no'},      True),\n",
    "        ({'Tempo':'Chuvoso','Temperatura':'Fria','Umidade':'Normal','Ventoso':'yes'},    False),\n",
    "        ({'Tempo':'Nublado','Temperatura':'Fria','Umidade':'Normal','Ventoso':'yes'},        True),\n",
    "        ({'Tempo':'Ensolarado','Temperatura':'Amena','Umidade':'Alta','Ventoso':'no'}, False),\n",
    "        ({'Tempo':'Ensolarado','Temperatura':'Fria','Umidade':'Normal','Ventoso':'no'},      True),\n",
    "        ({'Tempo':'Chuvoso','Temperatura':'Amena','Umidade':'Normal','Ventoso':'no'}, True),\n",
    "        ({'Tempo':'Ensolarado','Temperatura':'Amena','Umidade':'Normal','Ventoso':'yes'},True),\n",
    "        ({'Tempo':'Nublado','Temperatura':'Amena','Umidade':'Alta','Ventoso':'yes'},    True),\n",
    "    ]\n",
    "    \n",
    "    print(\"[INFO] Construindo a árvore:\")\n",
    "    tree = build_tree_id3(inputs)\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Uma função para percorrer a árvore de decisão treinada e realizar a classificação de uma nova instância (do conjunto de teste);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Dados de amostras (ultimas duas linhas) para teste de resultado:\n",
      "Nublado / Quente / Normal / Falso -> True\n",
      "Chuvoso / Amena / Alta / Verdadeiro -> False\n"
     ]
    }
   ],
   "source": [
    "def classify(tree, input):\n",
    "    \"\"\"classify the input using the given decision tree\"\"\"\n",
    "\n",
    "    # if this is a leaf node, return its value\n",
    "    if tree in [True, False]:\n",
    "        return tree\n",
    "\n",
    "    # otherwise find the correct subtree\n",
    "    attribute, subtree_dict = tree\n",
    "\n",
    "    subtree_key = input.get(attribute)  # None if input is missing attribute\n",
    "\n",
    "    if subtree_key not in subtree_dict: # if no subtree for key,\n",
    "        subtree_key = None              # we'll use the None subtree\n",
    "\n",
    "    subtree = subtree_dict[subtree_key] # choose the appropriate subtree\n",
    "    return classify(subtree, input)     # and use it to classify the input\n",
    "\n",
    "print('\\n')\n",
    "print('[INFO] Dados de amostras (ultimas duas linhas) para teste de resultado:')\n",
    "print(\"Nublado / Quente / Normal / Falso ->\", classify(tree,\n",
    "    { \"Tempo\" : \"Nublado\",\n",
    "      \"Temperatura\" : \"Quente\",\n",
    "      \"Umidade\" : \"Normal\",\n",
    "      \"Ventoso\" : \"no\"} ))\n",
    "\n",
    "print(\"Chuvoso / Amena / Alta / Verdadeiro ->\", classify(tree,\n",
    "    { \"Tempo\" : \"Chuvoso\",\n",
    "      \"Temperatura\" : \"Amena\",\n",
    "      \"Umidade\" : \"Alta\",\n",
    "      \"Ventoso\" : \"yes\"} ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. O mecanismo de bootstrap (amostragem com reposição) para geração de subconjuntos a partir do conjunto de dados de treinamento originais. Cada bootstrap será utilizado para o treinamento de uma árvore no aprendizado ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. O mecanismo de amostragem de m atributos a cada divisão de nó, a partir dos quais será selecionado o melhor atributo de acordo com o critério de Ganho de Informação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. O treinamento de um ensemble de árvores de decisão, adotando os mecanismos de bootstrap e seleção de atributos com amostragem, como mencionados acima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. O mecanismo de votação majoritária entre as múltiplas árvores de decisão no ensemble, para classificação de novas instâncias utilizando o modelo de Florestas Aleatórias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. A técnica de validação cruzada (cross-validation) estratificada, para avaliar poder de generalização do modelo e a variação de desempenho de acordo com diferentes valores para os parâmetros do algoritmo (ex., número de árvores no ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Avaliação do impacto do número de árvores no desempenho do ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
