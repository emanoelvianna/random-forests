{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprendizado Ensemble - Florestas Aleatórias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bibliotecas utilizadas no desenvolvimento do projeto\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "from functools import partial\n",
    "import math, random\n",
    "import pandas as pd\n",
    "from csv import reader\n",
    "import numpy as np\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_dataset(path_file): \n",
    "    dataset = list()\n",
    "    with open(path_file, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        rows = [r for r in csv_reader]\n",
    "    # capturando os cabeçalhos\n",
    "    headers = rows[0]\n",
    "        \n",
    "    for row in rows[1:len(rows)]:\n",
    "        out_dic = {}\n",
    "        for header_index in range(len(headers)):\n",
    "            out_dic.update({ headers[header_index]: row[header_index]})\n",
    "        \n",
    "        # captura a classe\n",
    "        class_key = list(out_dic.items())[-1]\n",
    "        # remove a classe captura do dicionario\n",
    "        del out_dic[list(out_dic.keys())[-1]]\n",
    "        # montando o dataset de saída\n",
    "        data_tuple = (out_dic, class_key[1])\n",
    "        dataset.append(data_tuple)\n",
    "    return dataset    \n",
    "\n",
    "# construindo a base de dados a partir do arquivo fornecido\n",
    "dataset = build_dataset('datasets/benchmark.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def entropy(class_probabilities):\n",
    "    \"\"\"given a list of class probabilities, compute the entropy\"\"\"\n",
    "    return sum(-p * math.log(p, 2) for p in class_probabilities if p)\n",
    "\n",
    "def class_probabilities(labels):\n",
    "    total_count = len(labels)\n",
    "    return [count / total_count\n",
    "            for count in Counter(labels).values()]\n",
    "\n",
    "def data_entropy(labeled_data):\n",
    "    labels = [label for _, label in labeled_data]\n",
    "    probabilities = class_probabilities(labels)\n",
    "    return entropy(probabilities)\n",
    "\n",
    "def partition_entropy(subsets):\n",
    "    \"\"\"find the entropy from this partition of data into subsets\"\"\"\n",
    "    total_count = sum(len(subset) for subset in subsets)\n",
    "\n",
    "    return sum( data_entropy(subset) * len(subset) / total_count for subset in subsets )\n",
    "\n",
    "def group_by(items, key_fn):\n",
    "    \"\"\"returns a defaultdict(list), where each input item is in the list whose key is key_fn(item)\"\"\"\n",
    "    groups = defaultdict(list)\n",
    "    for item in items:\n",
    "        key = key_fn(item)\n",
    "        groups[key].append(item)\n",
    "    return groups\n",
    "\n",
    "def partition_by(inputs, attribute):\n",
    "    \"\"\"returns a dict of inputs partitioned by the attribute each input is a pair (attribute_dict, label)\"\"\"\n",
    "    return group_by(inputs, lambda x: x[0][attribute])\n",
    "\n",
    "def partition_entropy_by(inputs, attribute):\n",
    "    \"\"\"computes the entropy corresponding to the given partition\"\"\"\n",
    "    partitions = partition_by(inputs, attribute)\n",
    "    return partition_entropy(partitions.values()) # retorna a media dos sub-conjuntos resultantes\n",
    "\n",
    "def gain(class_entropy, mean_entropy):\n",
    "    return class_entropy - mean_entropy;\n",
    "\n",
    "def class_entropy(inputs):\n",
    "    \"\"\"retorna a entropia sobre a classe\"\"\"\n",
    "    class_values = []\n",
    "    for item in inputs:\n",
    "        class_values.append(item[1]) # suponto a definição atual dos dados!\n",
    "    probabilities = class_probabilities(class_values)\n",
    "    class_entropy = entropy(probabilities)\n",
    "    return class_entropy\n",
    "\n",
    "def diff_class(inputs):\n",
    "    classes = []\n",
    "    for current_class in list(set([label for item, label in inputs if label])):\n",
    "        classes.append({'class': current_class, 'amount': 0})\n",
    "    for current_class in [label for item, label in inputs if label]:\n",
    "        for my_class in classes:\n",
    "            if(my_class['class']  == current_class):\n",
    "                my_class['amount'] = my_class['amount'] + 1\n",
    "    return classes\n",
    "\n",
    "def highest_class(classes):\n",
    "    my_class = classes[0]\n",
    "    for current_class in classes:\n",
    "        if(current_class['amount'] > my_class['amount']):\n",
    "            my_class = current_class\n",
    "    return my_class\n",
    "    \n",
    "\n",
    "def build_tree(inputs, split_candidates=None):\n",
    "\n",
    "    # if this is our first pass,\n",
    "    # all keys of the first input are split candidates\n",
    "    if split_candidates is None:\n",
    "        split_candidates = inputs[0][0].keys()\n",
    "              \n",
    "    # obtendo as classes\n",
    "    # [(classe, quantidade)]\n",
    "    classes = diff_class(inputs)\n",
    "    \n",
    "    # count Trues and Falses in the inputs\n",
    "    num_inputs = len(inputs)\n",
    "    num_trues = len([label for item, label in inputs if label])\n",
    "    num_falses = num_inputs - num_trues\n",
    "    \n",
    "    # verificando a homogeneidade do cojunto\n",
    "    if(len(classes) == 1):\n",
    "        return classes[0]['class']\n",
    "\n",
    "    if not split_candidates:          # if no split candidates left\n",
    "        return highest_class(classes) # return the majority leaf\n",
    "\n",
    "    # otherwise, split on the best attribute\n",
    "    \n",
    "    best_gain = 0\n",
    "    best_attribute = None\n",
    "    for candidate in split_candidates:\n",
    "        mean_entropy = partition_entropy_by(inputs, candidate)\n",
    "        #print('[INFO] Atributo: ', candidate, '- entropia média: ', mean_entropy)\n",
    "        gain_result = gain(class_entropy(inputs), mean_entropy)\n",
    "        #print('[INFO] Atributo: ', candidate, '- ganho: ', gain_result)\n",
    "        if(gain_result > best_gain):\n",
    "            best_gain = gain(class_entropy(inputs), mean_entropy)\n",
    "            best_attribute = candidate\n",
    "        #print('--')\n",
    "    \n",
    "    #print('----------------------------------------')\n",
    "    #print('[INFO] best_attribute: ', best_attribute)\n",
    "    #print('----------------------------------------')\n",
    "    partitions = partition_by(inputs, best_attribute)\n",
    "    new_candidates = [a for a in split_candidates\n",
    "                      if a != best_attribute]\n",
    "\n",
    "    # recursively build the subtrees\n",
    "    subtrees = { attribute : build_tree(subset, new_candidates)\n",
    "                 for attribute, subset in partitions.items() }\n",
    "\n",
    "    #subtrees[None] = num_trues > num_falses # default case\n",
    "\n",
    "    return (best_attribute, subtrees)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # construindo a árvore sobre os dados construindos anteriormente\n",
    "    tree = build_tree(dataset)\n",
    "    #print('\\n')\n",
    "    #print('----------------------------------------')\n",
    "    #print(\"[INFO] Árvore construida:\")\n",
    "    #print('----------------------------------------')\n",
    "    #print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Digraph('G', filename='tree.gv')\n",
    "\n",
    "g.edge('Tempo, ganho 0.970', 'Umidade', label='Ensolarado, ganho: 0.970')\n",
    "g.edge('Umidade', 'Não', label='Alta')\n",
    "g.edge('Umidade', 'Sim', label='Normal')\n",
    "g.edge('Tempo, ganho 0.970', 'Sim', label='Nublado')\n",
    "g.edge('Tempo, ganho 0.970', 'Ventoso', label='Nublado, ganho: 0.970')\n",
    "g.edge('Ventoso', 'Sim', label='Falso')\n",
    "g.edge('Ventoso', 'Nao', label='Verdadeiro')\n",
    "\n",
    "#g.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Dados de amostras (ultimas duas linhas) para teste de resultado:\n",
      "Nublado / Quente / Normal / Falso -> Sim\n",
      "Chuvoso / Amena / Alta / Verdadeiro -> Nao\n"
     ]
    }
   ],
   "source": [
    "def classify(tree, classes, input):\n",
    "    \"\"\"classificar a entrada usando a árvore de decisão fornecida\"\"\"\n",
    "\n",
    "    # se este é um nó folha, retorna seu valor\n",
    "    if tree in classes:\n",
    "        return tree\n",
    "\n",
    "    # caso contrário, encontre a subárvore correta\n",
    "    attribute, subtree_dict = tree\n",
    "\n",
    "    subtree_key = input.get(attribute)  # Nenhum se a entrada estiver faltando atributo\n",
    "\n",
    "    if subtree_key not in subtree_dict: # se não houver subárvore para a chave\n",
    "        subtree_key = None              # vamos usar a subárvore não\n",
    "\n",
    "    subtree = subtree_dict[subtree_key] # escolha a subárvore apropriada\n",
    "    return classify(subtree, classes, input) # e usá-lo para classificar a entrada\n",
    "\n",
    "\n",
    "# obtendo as classes possiveis para a àrvore\n",
    "classes = list(set([label for item, label in dataset if label]))\n",
    "\n",
    "print('\\n')\n",
    "print('[INFO] Dados de amostras (ultimas duas linhas) para teste de resultado:')\n",
    "\n",
    "print('Nublado / Quente / Normal / Falso ->', classify(tree, classes,\n",
    "    { 'Tempo' : 'Nublado',\n",
    "      'Temperatura' : 'Quente',\n",
    "      'Umidade' : 'Normal',\n",
    "      'Ventoso' : 'Falso'} ))\n",
    "print('Chuvoso / Amena / Alta / Verdadeiro ->', classify(tree, classes,\n",
    "    { 'Tempo' : 'Chuvoso',\n",
    "      'Temperatura' : 'Amena',\n",
    "      'Umidade' : 'Alta',\n",
    "      'Ventoso' : 'Verdadeiro'} ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(dataset):\n",
    "    bootstrap = dataset.sample(n = len(dataset), replace = True)\n",
    "    return bootstrap\n",
    "\n",
    "result_bootstrap = bootstrap(pd.read_csv('datasets/voting.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for _ in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    "\n",
    "result_cross = cross_validation_split(result_bootstrap.values.tolist(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] definindo folds para teste\n",
      "\n",
      "[INFO] definindo folds para treino\n"
     ]
    }
   ],
   "source": [
    "# TODO: DIVISÃO TREINO E TESTE\n",
    "def train_split(dataset, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        return train_set\n",
    "\n",
    "def test_split(dataset, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    for fold in folds:\n",
    "        test_set = list(fold)\n",
    "        return test_set\n",
    "\n",
    "\n",
    "# Não está retendo os dados do banco de bootstrap, é os mesmos dados, mas ainda tá flutuando e gerando listas diferentes, temos que discutir se isso tem algum problema \n",
    "\n",
    "\n",
    "test_set = test_split(result_cross, 10) \n",
    "print('[INFO] definindo folds para teste')\n",
    "\n",
    "print('\\n[INFO] definindo folds para treino')\n",
    "train_set = train_split(result_cross, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_from_split(headers, dataset_from_bootstrap): \n",
    "    new_dataset = list()    \n",
    "    for row in dataset_from_bootstrap[0:len(dataset_from_bootstrap)]:\n",
    "        out_dic = {}\n",
    "        for header_index in range(len(headers)):\n",
    "            out_dic.update({ headers[header_index]: row[header_index]})\n",
    "        \n",
    "        # captura a classe\n",
    "        class_key = list(out_dic.items())[-1]\n",
    "        # remove a classe captura do dicionario\n",
    "        del out_dic[list(out_dic.keys())[-1]]\n",
    "        # montando o dataset de saída\n",
    "        data_tuple = (out_dic, class_key[1])\n",
    "        new_dataset.append(data_tuple)\n",
    "    return new_dataset\n",
    "\n",
    "# obtebdo os cabeçalhos\n",
    "headers = result_bootstrap.columns.tolist()\n",
    "#print(build_tree(build_from_bootstrap(headers, result_bootstrap.values.tolist())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pre_dataset(old_dataset):\n",
    "    new_dataset = list()\n",
    "    for i in old_dataset:\n",
    "        for j in i:\n",
    "            new_dataset.append(j)\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construindo a árvore a partir do split vindo do cross\n",
    "new_train = build_pre_dataset(train_set) # treino\n",
    "\n",
    "new_tree_from_train = build_tree(build_from_split(headers, new_train))\n",
    "\n",
    "# construindo a árvore a partir do split vindo do cross\n",
    "new_test = build_pre_dataset(test_set) # teste\n",
    "        \n",
    "classes = list(set([label for item, label in build_from_split(headers, new_train) if label]))\n",
    "     \n",
    "classe_teste = list()\n",
    "preditos_teste = list()\n",
    "for current in build_from_split(headers, new_test):\n",
    "    preditos_teste.append(current[1])\n",
    "    classe_teste.append(classify(new_tree_from_train, classes, current[0]))\n",
    "  \n",
    "#print('\\n[INFO] resultado real dos dados de teste: ')\n",
    "#print(classe_teste)\n",
    "#print('\\n[INFO] resultado preditos esperado: ')\n",
    "#print(preditos_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25  0]\n",
      " [ 0 18]]\n",
      "\n",
      "Média da acurácia: 1.00%\n",
      "Média da Recall: 1.00%\n",
      "Média da Precisão: 1.00%\n",
      "Média da f-score: 1.00%\n",
      "\n",
      "Desvio padrão da acurácia: 0.00%\n",
      "Desvio padrão da Recall: 0.00%\n",
      "Desvio padrão da Precisão: 0.00%\n",
      "Desvio padrão da f-score: 0.00%\n"
     ]
    }
   ],
   "source": [
    "matrix = list()\n",
    "accuracy = list()\n",
    "recall = list()\n",
    "precision = list()\n",
    "score = list()\n",
    "\n",
    "def classification_report(classe_teste, preditos_teste):\n",
    "    true_class = 'democrat'\n",
    "    negative_class = 'republican'\n",
    "    # declarando a frêquencia\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for (indice, v_real) in enumerate(classe_teste):\n",
    "        v_predito = preditos_teste[indice]\n",
    "        # se trata de um valor real da classe positiva\n",
    "        if v_real == true_class:\n",
    "            tp += 1 if v_predito == v_real else 0\n",
    "            fp += 1 if v_predito != v_real else 0\n",
    "        else:\n",
    "            tn += 1 if v_predito == v_real else 0\n",
    "            fn += 1 if v_predito != v_real else 0\n",
    "                \n",
    "    # calculando os valores de frêquencia\n",
    "    accuracy.append((tp+tn)/(tp+fp+tn+fn))\n",
    "    recall.append(tp/(tp+fn))\n",
    "    precision.append(tp/(tp+fp))\n",
    "    score.append(2*tp/(2*tp+fp+fn))\n",
    "    \n",
    "    # desenhando a matriz de confusão\n",
    "    print(np.array([\n",
    "        [ tp, fp ],\n",
    "        [ fn, tn ]\n",
    "    ]))\n",
    "    \n",
    "classification_report(classe_teste, preditos_teste)\n",
    "print('')\n",
    "print('Média da acurácia: %.2f%%' % (sum(accuracy)/float(len(accuracy))))\n",
    "print('Média da Recall: %.2f%%' % (sum(recall)/float(len(recall))))\n",
    "print('Média da Precisão: %.2f%%' % (sum(precision)/float(len(precision))))\n",
    "print('Média da f-score: %.2f%%' % (sum(score)/float(len(score))))\n",
    "print('')\n",
    "print(\"Desvio padrão da acurácia: {:.2f}%\".format(np.std(accuracy)*100))\n",
    "print(\"Desvio padrão da Recall: {:.2f}%\".format(np.std(recall)*100))\n",
    "print(\"Desvio padrão da Precisão: {:.2f}%\".format(np.std(precision)*100))\n",
    "print(\"Desvio padrão da f-score: {:.2f}%\".format(np.std(score)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: FLORESTAS ALEATÓRIAS\n",
    "\n",
    "dados_originais = pd.read_csv('datasets/voting.csv')\n",
    "\n",
    "n_trees = 15\n",
    "my_tress = list()\n",
    "my_cases_for_test = list()\n",
    "for n in range(n_trees):\n",
    "    n_bootstrap = bootstrap(dados_originais)       \n",
    "    n_cross = cross_validation_split(n_bootstrap.values.tolist(), 10)\n",
    "    my_cases_for_test.append(build_pre_dataset(test_split(n_cross, 10)))\n",
    "    train_set = train_split(n_cross, 10)\n",
    "    new_tree_from_train = build_tree(build_from_split(headers, new_train))\n",
    "    my_tress.append(new_tree_from_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forest_classify(trees, classes, input):\n",
    "    votes = [classify(tree, classes, input) for tree in trees]\n",
    "    vote_counts = Counter(votes)\n",
    "    return vote_counts.most_common(1)[0][0]\n",
    "\n",
    "classe_teste = list()\n",
    "preditos_teste = list()\n",
    "for current in build_from_split(headers, my_cases_for_test[0]):\n",
    "    preditos_teste.append(current[1])\n",
    "    classe_teste.append(forest_classify(my_tress, classes, current[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26  0]\n",
      " [ 0 17]]\n",
      "\n",
      "Média da acurácia: 1.00%\n",
      "Média da Recall: 1.00%\n",
      "Média da Precisão: 1.00%\n",
      "Média da f-score: 1.00%\n",
      "\n",
      "Desvio padrão da acurácia: 0.00%\n",
      "Desvio padrão da Recall: 0.00%\n",
      "Desvio padrão da Precisão: 0.00%\n",
      "Desvio padrão da f-score: 0.00%\n"
     ]
    }
   ],
   "source": [
    "classification_report(classe_teste, preditos_teste)\n",
    "print('')\n",
    "print('Média da acurácia: %.2f%%' % (sum(accuracy)/float(len(accuracy))))\n",
    "print('Média da Recall: %.2f%%' % (sum(recall)/float(len(recall))))\n",
    "print('Média da Precisão: %.2f%%' % (sum(precision)/float(len(precision))))\n",
    "print('Média da f-score: %.2f%%' % (sum(score)/float(len(score))))\n",
    "print('')\n",
    "print(\"Desvio padrão da acurácia: {:.2f}%\".format(np.std(accuracy)*100))\n",
    "print(\"Desvio padrão da Recall: {:.2f}%\".format(np.std(recall)*100))\n",
    "print(\"Desvio padrão da Precisão: {:.2f}%\".format(np.std(precision)*100))\n",
    "print(\"Desvio padrão da f-score: {:.2f}%\".format(np.std(score)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
