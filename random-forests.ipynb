{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprendizado Ensemble - Florestas Aleatórias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bibliotecas utilizadas no desenvolvimento do projeto\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "from functools import partial\n",
    "import math, random\n",
    "import pandas as pd\n",
    "from csv import reader\n",
    "import numpy as np\n",
    "from random import seed\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_dataset(path_file): \n",
    "    dataset = list()\n",
    "    with open(path_file, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        rows = [r for r in csv_reader]\n",
    "    # capturando os cabeçalhos\n",
    "    headers = rows[0]\n",
    "    \n",
    "    remove_row_with_values_missing(rows, headers)\n",
    "    \n",
    "    for row in rows[1:len(rows)]:\n",
    "        out_dic = {}\n",
    "        for header_index in range(len(headers)):\n",
    "            out_dic.update({ headers[header_index]: row[header_index]})\n",
    "        \n",
    "        # captura a classe\n",
    "        class_key = list(out_dic.items())[-1]\n",
    "        # remove a classe captura do dicionario\n",
    "        del out_dic[list(out_dic.keys())[-1]]\n",
    "        # montando o dataset de saída\n",
    "        data_tuple = (out_dic, class_key[1])\n",
    "        dataset.append(data_tuple)\n",
    "    return dataset\n",
    "\n",
    "# TODO: devemos remover linhas com dados faltando?\n",
    "def remove_row_with_values_missing(rows, headers):\n",
    "    quant = 0\n",
    "    for row in rows[1:len(rows)]:\n",
    "        for header_index in range(len(headers)):\n",
    "            if(row[header_index] is None or row[header_index] == \"\"):\n",
    "                quant = quant + 1\n",
    "    \n",
    "\n",
    "# construindo a base de dados a partir do arquivo fornecido\n",
    "dataset = build_dataset('datasets/benchmark.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Desenvolvimento do algoritmo de indução de uma árvore de decisão, usando como critério de seleção de atributos para divisão de nós o **Ganho de Informação (baseado no conceito de entropia)**. **Tratando tanto atributos categóricos quanto numéricos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'class': 'Sim', 'amount': 9}, {'class': 'Nao', 'amount': 5}]\n",
      "{'class': 'Sim', 'amount': 9}\n",
      "[INFO] Atributo:  Tempo - entropia média:  0.6935361388961919\n",
      "[INFO] Atributo:  Tempo - ganho:  0.246749819774439\n",
      "--\n",
      "[INFO] Atributo:  Temperatura - entropia média:  0.9110633930116763\n",
      "[INFO] Atributo:  Temperatura - ganho:  0.029222565658954647\n",
      "--\n",
      "[INFO] Atributo:  Umidade - entropia média:  0.7884504573082896\n",
      "[INFO] Atributo:  Umidade - ganho:  0.15183550136234136\n",
      "--\n",
      "[INFO] Atributo:  Ventoso - entropia média:  0.8921589282623617\n",
      "[INFO] Atributo:  Ventoso - ganho:  0.04812703040826927\n",
      "--\n",
      "----------------------------------------\n",
      "[INFO] best_attribute:  Tempo\n",
      "----------------------------------------\n",
      "[{'class': 'Sim', 'amount': 2}, {'class': 'Nao', 'amount': 3}]\n",
      "{'class': 'Nao', 'amount': 3}\n",
      "[INFO] Atributo:  Temperatura - entropia média:  0.4\n",
      "[INFO] Atributo:  Temperatura - ganho:  0.5709505944546686\n",
      "--\n",
      "[INFO] Atributo:  Umidade - entropia média:  0.0\n",
      "[INFO] Atributo:  Umidade - ganho:  0.9709505944546686\n",
      "--\n",
      "[INFO] Atributo:  Ventoso - entropia média:  0.9509775004326938\n",
      "[INFO] Atributo:  Ventoso - ganho:  0.01997309402197478\n",
      "--\n",
      "----------------------------------------\n",
      "[INFO] best_attribute:  Umidade\n",
      "----------------------------------------\n",
      "[{'class': 'Nao', 'amount': 3}]\n",
      "{'class': 'Nao', 'amount': 3}\n",
      "[{'class': 'Sim', 'amount': 2}]\n",
      "{'class': 'Sim', 'amount': 2}\n",
      "[{'class': 'Sim', 'amount': 4}]\n",
      "{'class': 'Sim', 'amount': 4}\n",
      "[{'class': 'Sim', 'amount': 3}, {'class': 'Nao', 'amount': 2}]\n",
      "{'class': 'Sim', 'amount': 3}\n",
      "[INFO] Atributo:  Temperatura - entropia média:  0.9509775004326938\n",
      "[INFO] Atributo:  Temperatura - ganho:  0.01997309402197478\n",
      "--\n",
      "[INFO] Atributo:  Umidade - entropia média:  0.9509775004326938\n",
      "[INFO] Atributo:  Umidade - ganho:  0.01997309402197478\n",
      "--\n",
      "[INFO] Atributo:  Ventoso - entropia média:  0.0\n",
      "[INFO] Atributo:  Ventoso - ganho:  0.9709505944546686\n",
      "--\n",
      "----------------------------------------\n",
      "[INFO] best_attribute:  Ventoso\n",
      "----------------------------------------\n",
      "[{'class': 'Sim', 'amount': 3}]\n",
      "{'class': 'Sim', 'amount': 3}\n",
      "[{'class': 'Nao', 'amount': 2}]\n",
      "{'class': 'Nao', 'amount': 2}\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "[INFO] Árvore construida:\n",
      "----------------------------------------\n",
      "('Tempo', {'Ensolarado': ('Umidade', {'Alta': 'Nao', 'Normal': 'Sim'}), 'Nublado': 'Sim', 'Chuvoso': ('Ventoso', {'Falso': 'Sim', 'Verdadeiro': 'Nao'})})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def entropy(class_probabilities):\n",
    "    \"\"\"given a list of class probabilities, compute the entropy\"\"\"\n",
    "    return sum(-p * math.log(p, 2) for p in class_probabilities if p)\n",
    "\n",
    "def class_probabilities(labels):\n",
    "    total_count = len(labels)\n",
    "    return [count / total_count\n",
    "            for count in Counter(labels).values()]\n",
    "\n",
    "def data_entropy(labeled_data):\n",
    "    labels = [label for _, label in labeled_data]\n",
    "    probabilities = class_probabilities(labels)\n",
    "    return entropy(probabilities)\n",
    "\n",
    "def partition_entropy(subsets):\n",
    "    \"\"\"find the entropy from this partition of data into subsets\"\"\"\n",
    "    total_count = sum(len(subset) for subset in subsets)\n",
    "\n",
    "    return sum( data_entropy(subset) * len(subset) / total_count for subset in subsets )\n",
    "\n",
    "def group_by(items, key_fn):\n",
    "    \"\"\"returns a defaultdict(list), where each input item is in the list whose key is key_fn(item)\"\"\"\n",
    "    groups = defaultdict(list)\n",
    "    for item in items:\n",
    "        key = key_fn(item)\n",
    "        groups[key].append(item)\n",
    "    return groups\n",
    "\n",
    "def partition_by(inputs, attribute):\n",
    "    \"\"\"returns a dict of inputs partitioned by the attribute each input is a pair (attribute_dict, label)\"\"\"\n",
    "    return group_by(inputs, lambda x: x[0][attribute])\n",
    "\n",
    "def partition_entropy_by(inputs, attribute):\n",
    "    \"\"\"computes the entropy corresponding to the given partition\"\"\"\n",
    "    partitions = partition_by(inputs, attribute)\n",
    "    return partition_entropy(partitions.values()) # retorna a media dos sub-conjuntos resultantes\n",
    "\n",
    "def gain(class_entropy, mean_entropy):\n",
    "    return class_entropy - mean_entropy;\n",
    "\n",
    "def class_entropy(inputs):\n",
    "    \"\"\"retorna a entropia sobre a classe\"\"\"\n",
    "    class_values = []\n",
    "    for item in inputs:\n",
    "        class_values.append(item[1]) # suponto a definição atual dos dados!\n",
    "    probabilities = class_probabilities(class_values)\n",
    "    class_entropy = entropy(probabilities)\n",
    "    return class_entropy\n",
    "\n",
    "def diff_class(inputs):\n",
    "    classes = []\n",
    "    for current_class in list(set([label for item, label in inputs if label])):\n",
    "        classes.append({'class': current_class, 'amount': 0})\n",
    "    for current_class in [label for item, label in inputs if label]:\n",
    "        for my_class in classes:\n",
    "            if(my_class['class']  == current_class):\n",
    "                my_class['amount'] = my_class['amount'] + 1\n",
    "    return classes\n",
    "\n",
    "def highest_class(classes):\n",
    "    my_class = classes[0]\n",
    "    for current_class in classes:\n",
    "        if(current_class['amount'] > my_class['amount']):\n",
    "            my_class = current_class\n",
    "    return my_class\n",
    "    \n",
    "\n",
    "def build_tree_id3(inputs, split_candidates=None):\n",
    "\n",
    "    # if this is our first pass,\n",
    "    # all keys of the first input are split candidates\n",
    "    if split_candidates is None:\n",
    "        split_candidates = inputs[0][0].keys()\n",
    "              \n",
    "    # obtendo as classes\n",
    "    # [(classe, quantidade)]\n",
    "    classes = diff_class(inputs)\n",
    "    print(classes)\n",
    "    print(highest_class(classes))\n",
    "    \n",
    "    # count Trues and Falses in the inputs\n",
    "    num_inputs = len(inputs)\n",
    "    num_trues = len([label for item, label in inputs if label])\n",
    "    num_falses = num_inputs - num_trues\n",
    "    \n",
    "    # verificando a homogeneidade do cojunto\n",
    "    if(len(classes) == 1):\n",
    "        return classes[0]['class']\n",
    "\n",
    "    if not split_candidates:          # if no split candidates left\n",
    "        return highest_class(classes) # return the majority leaf\n",
    "\n",
    "    # otherwise, split on the best attribute\n",
    "    \n",
    "    best_gain = 0\n",
    "    best_attribute = None\n",
    "    for candidate in split_candidates:\n",
    "        mean_entropy = partition_entropy_by(inputs, candidate)\n",
    "        print('[INFO] Atributo: ', candidate, '- entropia média: ', mean_entropy)\n",
    "        gain_result = gain(class_entropy(inputs), mean_entropy)\n",
    "        print('[INFO] Atributo: ', candidate, '- ganho: ', gain_result)\n",
    "        if(gain_result > best_gain):\n",
    "            best_gain = gain(class_entropy(inputs), mean_entropy)\n",
    "            best_attribute = candidate\n",
    "        print('--')\n",
    "    \n",
    "    print('----------------------------------------')\n",
    "    print('[INFO] best_attribute: ', best_attribute)\n",
    "    print('----------------------------------------')\n",
    "    partitions = partition_by(inputs, best_attribute)\n",
    "    new_candidates = [a for a in split_candidates\n",
    "                      if a != best_attribute]\n",
    "\n",
    "    # recursively build the subtrees\n",
    "    subtrees = { attribute : build_tree_id3(subset, new_candidates)\n",
    "                 for attribute, subset in partitions.items() }\n",
    "\n",
    "    #subtrees[None] = num_trues > num_falses # default case\n",
    "\n",
    "    return (best_attribute, subtrees)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # construindo a árvore sobre os dados construindos anteriormente\n",
    "    tree = build_tree_id3(dataset)\n",
    "    print('\\n')\n",
    "    print('----------------------------------------')\n",
    "    print(\"[INFO] Árvore construida:\")\n",
    "    print('----------------------------------------')\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Uma função para percorrer a árvore de decisão treinada e realizar a classificação de uma nova instância (do conjunto de teste);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Dados de amostras (ultimas duas linhas) para teste de resultado:\n",
      "Nublado / Quente / Normal / Falso -> Sim\n",
      "Chuvoso / Amena / Alta / Verdadeiro -> Nao\n"
     ]
    }
   ],
   "source": [
    "def classify(tree, classes, input):\n",
    "    \"\"\"classify the input using the given decision tree\"\"\"\n",
    "\n",
    "    # if this is a leaf node, return its value\n",
    "    if tree in classes:\n",
    "        return tree\n",
    "\n",
    "    # otherwise find the correct subtree\n",
    "    attribute, subtree_dict = tree\n",
    "\n",
    "    subtree_key = input.get(attribute)  # None if input is missing attribute\n",
    "\n",
    "    if subtree_key not in subtree_dict: # if no subtree for key,\n",
    "        subtree_key = None              # we'll use the None subtree\n",
    "\n",
    "    subtree = subtree_dict[subtree_key] # choose the appropriate subtree\n",
    "    return classify(subtree, classes, input)     # and use it to classify the input\n",
    "\n",
    "\n",
    "# obtendo as classes possiveis para a àrvore\n",
    "classes = list(set([label for item, label in dataset if label]))\n",
    "\n",
    "print('\\n')\n",
    "print('[INFO] Dados de amostras (ultimas duas linhas) para teste de resultado:')\n",
    "\n",
    "print('Nublado / Quente / Normal / Falso ->', classify(tree, classes,\n",
    "    { 'Tempo' : 'Nublado',\n",
    "      'Temperatura' : 'Quente',\n",
    "      'Umidade' : 'Normal',\n",
    "      'Ventoso' : 'Falso'} ))\n",
    "print('Chuvoso / Amena / Alta / Verdadeiro ->', classify(tree, classes,\n",
    "    { 'Tempo' : 'Chuvoso',\n",
    "      'Temperatura' : 'Amena',\n",
    "      'Umidade' : 'Alta',\n",
    "      'Ventoso' : 'Verdadeiro'} ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. O mecanismo de bootstrap (amostragem com reposição) para geração de subconjuntos a partir do conjunto de dados de treinamento originais. Cada bootstrap será utilizado para o treinamento de uma árvore no aprendizado ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(dataset):\n",
    "    bootstrap = dataset.sample(n = len(dataset), replace = True)\n",
    "    return bootstrap\n",
    "\n",
    "result_bootstrap = bootstrap(pd.read_csv('datasets/benchmark.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Nublado', 'Quente', 'Normal', 'Falso', 'Sim'],\n",
       "  ['Chuvoso', 'Amena', 'Alta', 'Verdadeiro', 'Nao']],\n",
       " [['Nublado', 'Amena', 'Alta', 'Verdadeiro', 'Sim'],\n",
       "  ['Chuvoso', 'Fria', 'Normal', 'Falso', 'Sim']],\n",
       " [['Nublado', 'Quente', 'Alta', 'Falso', 'Sim'],\n",
       "  ['Ensolarado', 'Quente', 'Alta', 'Falso', 'Nao']],\n",
       " [['Chuvoso', 'Fria', 'Normal', 'Verdadeiro', 'Nao'],\n",
       "  ['Ensolarado', 'Amena', 'Normal', 'Verdadeiro', 'Sim']],\n",
       " [['Chuvoso', 'Amena', 'Alta', 'Falso', 'Sim'],\n",
       "  ['Nublado', 'Quente', 'Alta', 'Falso', 'Sim']]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for _ in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    "\n",
    "cross_validation_split(result_bootstrap.values.tolist(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: DIVISÃO TREINO E TESTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_from_bootstrap(headers, dataset_from_bootstrap): \n",
    "    new_dataset = list()    \n",
    "    for row in dataset_from_bootstrap[0:len(dataset_from_bootstrap)]:\n",
    "        out_dic = {}\n",
    "        for header_index in range(len(headers)):\n",
    "            out_dic.update({ headers[header_index]: row[header_index]})\n",
    "        \n",
    "        # captura a classe\n",
    "        class_key = list(out_dic.items())[-1]\n",
    "        # remove a classe captura do dicionario\n",
    "        del out_dic[list(out_dic.keys())[-1]]\n",
    "        # montando o dataset de saída\n",
    "        data_tuple = (out_dic, class_key[1])\n",
    "        new_dataset.append(data_tuple)\n",
    "    return new_dataset\n",
    "\n",
    "# obtebdo os cabeçalhos\n",
    "headers = result_bootstrap.columns.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sim'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# print(build_tree_id3(build_from_bootstrap(headers, result_bootstrap.values.tolist())))\n",
    "\n",
    "# TODO: FLORESTAS ALEATÓRIAS\n",
    "\n",
    "def forest_classify(trees, classes, input):\n",
    "    votes = [classify(tree, classes, input) for tree in trees]\n",
    "    vote_counts = Counter(votes)\n",
    "    return vote_counts.most_common(1)[0][0]\n",
    "\n",
    "forest_classify([tree], classes, { 'Tempo' : 'Nublado',\n",
    "      'Temperatura' : 'Quente',\n",
    "      'Umidade' : 'Normal',\n",
    "      'Ventoso' : 'Falso'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. O mecanismo de amostragem de m atributos a cada divisão de nó, a partir dos quais será selecionado o melhor atributo de acordo com o critério de Ganho de Informação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. O treinamento de um ensemble de árvores de decisão, adotando os mecanismos de bootstrap e seleção de atributos com amostragem, como mencionados acima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. O mecanismo de votação majoritária entre as múltiplas árvores de decisão no ensemble, para classificação de novas instâncias utilizando o modelo de Florestas Aleatórias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. A técnica de validação cruzada (cross-validation) estratificada, para avaliar poder de generalização do modelo e a variação de desempenho de acordo com diferentes valores para os parâmetros do algoritmo (ex., número de árvores no ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Avaliação do impacto do número de árvores no desempenho do ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
