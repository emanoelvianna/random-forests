{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "9178afb9b3daeee402732af4e4aef10a7593df5184141cef26a75ebe4e69e442"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "dataset = pd.read_csv(\"C:/Users/renan/Desktop/UFRGS/Machine Learning/Trabalho1/random-forests-1/dataset.csv\") \n",
    "\n",
    "dir(dataset)\n",
    "\n",
    "print ('Banco com %d amostras e %d colunas\\n' % dataset.shape)\n",
    "\n",
    "print ('Tabela sumarizando as colunas do banco\\n')\n",
    "dataset.describe()"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 50,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Banco com 14 amostras e 5 colunas\n\nTabela sumarizando as colunas do banco\n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          Tempo Temperatura Umidade Ventoso Joga\n",
       "count        14          14      14      14   14\n",
       "unique        3           3       2       2    2\n",
       "top     Chuvoso       Amena    Alta   Falso  Sim\n",
       "freq          5           6       7       8    9"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tempo</th>\n      <th>Temperatura</th>\n      <th>Umidade</th>\n      <th>Ventoso</th>\n      <th>Joga</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>14</td>\n      <td>14</td>\n      <td>14</td>\n      <td>14</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>Chuvoso</td>\n      <td>Amena</td>\n      <td>Alta</td>\n      <td>Falso</td>\n      <td>Sim</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>5</td>\n      <td>6</td>\n      <td>7</td>\n      <td>8</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 50
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9402859586706311\n"
     ]
    }
   ],
   "source": [
    "def entropia(dataset):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculo da entropia do conjunto de dados.\n",
    "    Recebe como parâmetro o dataset. \n",
    "    \"\"\"\n",
    "\n",
    "    classe = dataset.keys()[-1]   #Define a variável alvo como classe\n",
    "    entropy = 0\n",
    "    values = dataset[classe].unique()\n",
    "    for value in values:\n",
    "        fraction = dataset[classe].value_counts()[value]/len(dataset[classe])\n",
    "        entropy += -fraction*np.log2(fraction)\n",
    "    return entropy\n",
    "\n",
    "#Teste dos valores gerados pela função \n",
    "teste_entropia = entropia(dataset)\n",
    "print (teste_entropia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Tempo': 0.6935361388961914, 'Temperatura': 0.9110633930116756, 'Umidade': 0.7884504573082889, 'Ventoso': 0.892158928262361}\n"
     ]
    }
   ],
   "source": [
    "eps = np.finfo(float).eps\n",
    "from numpy import log2 as log\n",
    "\n",
    "def entropia_atributos(dataset, attribute):\n",
    "    \n",
    "    classe = dataset.keys()[-1]   \n",
    "    target_variables = dataset[classe].unique()  \n",
    "    variables = dataset[attribute].unique()  \n",
    "    entropy_attribute = 0\n",
    "    \n",
    "    for variable in variables:\n",
    "        entropy_each_feature = 0\n",
    "        for target_variable in target_variables:\n",
    "            num = len(dataset[attribute][dataset[attribute] == variable][dataset[Class] == target_variable]) \n",
    "            den = len(dataset[attribute][dataset[attribute] == variable]) \n",
    "            fraction = num/(den + eps)  \n",
    "            entropy_each_feature += -fraction*log(fraction + eps) \n",
    "        fraction2 = den/len(dataset)\n",
    "        entropy_attribute += -fraction2*entropy_each_feature\n",
    "\n",
    "    return(abs(entropy_attribute))\n",
    "\n",
    "#Teste dos valores gerados pela função \n",
    "teste_entrobia_atributos = {k:ent(dataset,k) for k in dataset.keys()[:-1]}\n",
    "print (teste_entrobia_atributos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Tempo': 0.24674981977443977, 'Temperatura': 0.029222565658955535, 'Umidade': 0.15183550136234225, 'Ventoso': 0.048127030408270155}\n"
     ]
    }
   ],
   "source": [
    "def ganho_de_informacao(dataset):\n",
    "\n",
    "    IG = []\n",
    "\n",
    "    for key in dataset.keys()[:-1]:\n",
    "        IG.append(entropia(dataset)-entropia_atributos(dataset,key))\n",
    "    return dataset.keys()[:-1][np.argmax(IG)]\n",
    "\n",
    "#Teste dos valores gerados pela função\n",
    "print (IG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'Class' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-57dd826634b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mteste\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecision_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-62-57dd826634b6>\u001b[0m in \u001b[0;36mdecision_tree\u001b[1;34m(dataset, tree)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mclasse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mganho_de_informacao\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mattValue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-61-6c6a12c01314>\u001b[0m in \u001b[0;36mganho_de_informacao\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mIG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentropia\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mentropia_atributos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-52-5f45828c74f2>\u001b[0m in \u001b[0;36mentropia_atributos\u001b[1;34m(dataset, attribute)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mentropy_each_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtarget_variable\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtarget_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mattribute\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mattribute\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mvariable\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mClass\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtarget_variable\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0mden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mattribute\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mattribute\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mvariable\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mfraction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mden\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Class' is not defined"
     ]
    }
   ],
   "source": [
    "def gerar_particao(dataset, node, value):\n",
    "  return dataset[dataset[node] == value].reset_index(drop=True)\n",
    "  \n",
    "  \n",
    "def decision_tree(dataset, tree = None): \n",
    "    \n",
    "    classe = dataset.keys()[-1]\n",
    "    node = ganho_de_informacao(dataset)\n",
    "    attValue = np.unique(dataset[node])\n",
    "        \n",
    "    if tree is None:                    \n",
    "        tree={}\n",
    "        tree[node] = {} \n",
    "\n",
    "    for value in attValue:\n",
    "        \n",
    "        subtable = gerar_particao(dataset, node, value)\n",
    "        clValue,counts = np.unique(subtable['Eat'],return_counts=True)                        \n",
    "        \n",
    "        if len(counts)==1:\n",
    "            tree[node][value] = clValue[0]                                                    \n",
    "        else:        \n",
    "            tree[node][value] = decision_tree(subtable)\n",
    "                   \n",
    "    return tree\n",
    "\n",
    "teste = decision_tree(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}