{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "9178afb9b3daeee402732af4e4aef10a7593df5184141cef26a75ebe4e69e442"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "To fazendo alguns testes separados aqui nesse notebook, vou tentar fazer esse teste de exemplo que tem no pdf novo que subi, que tá no moodle. Acho que as duas principais coisas que temos que resolver é conseguir executar uma arvore de decisão simples com esses dados de benchmark e fazer um cross validation com algum outro tipo de dado, pq o meu do exercício anterior não deu certo.\n",
    "\n",
    "Vou seguir fazendo esse exemplo aqui, depois se puder sobe teu trabalho de crossvalidation pra gente já começar a ajustar caso não esteja fazendo aquela divisão estratificada que falamos aquele dia. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "dataset = pd.read_csv(\"C:/Users/renan/Desktop/UFRGS/Machine Learning/Trabalho1/random-forests-1/dataset.csv\") \n",
    "\n",
    "dir(dataset)\n",
    "\n",
    "print ('Banco com %d amostras e %d colunas\\n' % dataset.shape)\n",
    "\n",
    "print ('Tabela sumarizando as colunas do banco\\n')\n",
    "dataset.describe()"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Banco com 14 amostras e 5 colunas\n\nTabela sumarizando as colunas do banco\n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          Tempo Temperatura Umidade Ventoso Joga\n",
       "count        14          14      14      14   14\n",
       "unique        3           3       2       2    2\n",
       "top     Chuvoso       Amena  Normal   Falso  Sim\n",
       "freq          5           6       7       8    9"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tempo</th>\n      <th>Temperatura</th>\n      <th>Umidade</th>\n      <th>Ventoso</th>\n      <th>Joga</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>14</td>\n      <td>14</td>\n      <td>14</td>\n      <td>14</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>Chuvoso</td>\n      <td>Amena</td>\n      <td>Normal</td>\n      <td>Falso</td>\n      <td>Sim</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>5</td>\n      <td>6</td>\n      <td>7</td>\n      <td>8</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9402859586706311\n"
     ]
    }
   ],
   "source": [
    "def entropy(dataset):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculo da entropia do conjunto de dados.\n",
    "    Recebe como parâmetro o dataset. \n",
    "    \"\"\"\n",
    "\n",
    "    Class = dataset.keys()[-1]   #Define a variável alvo como Class\n",
    "    entropy = 0\n",
    "    values = dataset[Class].unique()\n",
    "    for value in values:\n",
    "        fraction = dataset[Class].value_counts()[value]/len(dataset[Class])\n",
    "        entropy += -fraction*np.log2(fraction)\n",
    "    return entropy\n",
    "\n",
    "#Teste dos valores gerados pela função \n",
    "teste_entropia = entropy(dataset)\n",
    "print (teste_entropia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9402859586706311\n"
     ]
    }
   ],
   "source": [
    "result = entropy(dataset)\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entropy_attribute(df,attribute):\n",
    "  Class = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
    "  target_variables = df[Class].unique()  #This gives all 'Yes' and 'No'\n",
    "  variables = df[attribute].unique()    #This gives different features in that attribute (like 'Hot','Cold' in Temperature)\n",
    "  entropy2 = 0\n",
    "  for variable in variables:\n",
    "      entropy = 0\n",
    "      for target_variable in target_variables:\n",
    "          num = len(df[attribute][df[attribute]==variable][df[Class] ==target_variable])\n",
    "          den = len(df[attribute][df[attribute]==variable])\n",
    "          fraction = num/(den+eps)\n",
    "          entropy += -fraction*log(fraction+eps)\n",
    "      fraction2 = den/len(df)\n",
    "      entropy2 += -fraction2*entropy\n",
    "  return abs(entropy2)\n",
    "\n",
    "\n",
    "def find_winner(df):\n",
    "    Entropy_att = []\n",
    "    IG = []\n",
    "    for key in df.keys()[:-1]:\n",
    "#         Entropy_att.append(find_entropy_attribute(df,key))\n",
    "        IG.append(find_entropy(df)-find_entropy_attribute(df,key))\n",
    "    return df.keys()[:-1][np.argmax(IG)]\n",
    "  \n",
    "  \n",
    "def get_subtable(df, node,value):\n",
    "  return df[df[node] == value].reset_index(drop=True)\n",
    "\n",
    "\n",
    "def buildTree(df,tree=None): \n",
    "    Class = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
    "    \n",
    "    #Here we build our decision tree\n",
    "\n",
    "    #Get attribute with maximum information gain\n",
    "    node = find_winner(df)\n",
    "    \n",
    "    #Get distinct value of that attribute e.g Salary is node and Low,Med and High are values\n",
    "    attValue = np.unique(df[node])\n",
    "    \n",
    "    #Create an empty dictionary to create tree    \n",
    "    if tree is None:                    \n",
    "        tree={}\n",
    "        tree[node] = {}\n",
    "    \n",
    "   #We make loop to construct a tree by calling this function recursively. \n",
    "    #In this we check if the subset is pure and stops if it is pure. \n",
    "\n",
    "    for value in attValue:\n",
    "        \n",
    "        subtable = get_subtable(df,node,value)\n",
    "        clValue,counts = np.unique(subtable['Eat'],return_counts=True)                        \n",
    "        \n",
    "        if len(counts)==1:#Checking purity of subset\n",
    "            tree[node][value] = clValue[0]                                                    \n",
    "        else:        \n",
    "            tree[node][value] = buildTree(subtable) #Calling the function recursively \n",
    "                   \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}